# -*- coding: utf-8 -*-
"""The Data Engineering ETL Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Txn1XyPDsmwar-CNi7720DBl48QSCl1W
"""

# Create folder structure
import os

BASE = "/content/project3"
RAW_DIR = os.path.join(BASE, "data", "raw")
STAGING_DIR = os.path.join(BASE, "data", "staging")
OUT_DIR = os.path.join(BASE, "outputs", "visuals")

os.makedirs(RAW_DIR, exist_ok=True)
os.makedirs(STAGING_DIR, exist_ok=True)
os.makedirs(OUT_DIR, exist_ok=True)

print("Folder structure created.")
print("RAW_DIR:", RAW_DIR)

# Verify CSV files exist
import glob

files = sorted(glob.glob(RAW_DIR + "/*.csv"))
print("CSV files found:")
for f in files:
    print(" -", f)

# Define the load_csv function
def load_csv(name):
    path = os.path.join(RAW_DIR, name)
    if not os.path.exists(path):
        raise FileNotFoundError(f"{name} not found in RAW_DIR")
    # Load the csv from the correct path
    return pd.read_csv(path, low_memory=False)

print("load_csv function defined.")

!mv /content/olist_*.csv {RAW_DIR}
!mv /content/product_category_name_translation.csv {RAW_DIR}

BASE = "/content/project3"
RAW_DIR = os.path.join(BASE, "data", "raw")
STAGING_DIR = os.path.join(BASE, "data", "staging")
OUT_DIR = os.path.join(BASE, "outputs", "visuals")

os.makedirs(RAW_DIR, exist_ok=True)
os.makedirs(STAGING_DIR, exist_ok=True)
os.makedirs(OUT_DIR, exist_ok=True)

print("RAW_DIR:", RAW_DIR)

import shutil
import glob

# path where your files are currently located
source_files = glob.glob("/content/*.csv")

for f in source_files:
    shutil.move(f, RAW_DIR)
    print("Moved:", f)

import glob
print("Files in RAW_DIR:")
for f in glob.glob(RAW_DIR + "/*.csv"):
    print(f)

print(RAW_DIR)
!ls -R /content/project3/data/raw

RAW_DIR = "/content/project3/data/raw"
print("RAW_DIR:", RAW_DIR)
import os
print("Exists:", os.path.isdir(RAW_DIR))
print()

#Search for all CSV files in common locations and show them
import glob
search_paths = [
    "/content/**/*.csv",
    "/root/**/*.csv",
    "/mnt/**/*.csv",
    "/usr/**/*.csv",
    "/home/**/*.csv"
]
found = []
for p in search_paths:
    found += glob.glob(p, recursive=True)
found = sorted(set(found))

print("Found CSV files (first 200 shown):", len(found))
for f in found[:200]:
    print(f)
print()

# If none found above, also list top-level /content
if len(found) == 0:
    print("No CSVs found in searched paths. Listing /content top-level:")
    for f in sorted(glob.glob("/content/*")):
        print(f)
    print()

# Copy all discovered CSVs into RAW_DIR
import shutil
copied = 0
for f in found:
    try:
        dest = os.path.join(RAW_DIR, os.path.basename(f))
        # if file already exists, overwrite to be safe
        shutil.copy2(f, dest)
        copied += 1
    except Exception as e:
        print("Error copying", f, "->", e)

print(f"Copied {copied} files into {RAW_DIR}")
print()

# List files now inside RAW_DIR
print("Files now in RAW_DIR:")
for f in sorted(glob.glob(RAW_DIR + "/*.csv")):
    print(f)

from google.colab import files
uploaded = files.upload()  # select the CSV files from your computer
# move uploads into RAW_DIR
import os, shutil
os.makedirs(RAW_DIR, exist_ok=True)
for fn in uploaded.keys():
    src = "/content/" + fn
    dst = os.path.join(RAW_DIR, fn)
    shutil.move(src, dst)
    print("Moved uploaded file to:", dst)
# verify
print("Files in RAW_DIR after upload:")
import glob
for f in glob.glob(RAW_DIR + "/*.csv"):
    print(f)

orders_df = load_csv("olist_orders_dataset.csv")
items_df = load_csv("olist_order_items_dataset.csv")
customers_df = load_csv("olist_customers_dataset.csv")
payments_df = load_csv("olist_order_payments_dataset.csv")
products_df = load_csv("olist_products_dataset.csv")
translation_df = load_csv("product_category_name_translation.csv")

print("All files loaded successfully.")
reviews_df = load_csv("olist_order_reviews_dataset.csv")

from google.colab import drive
drive.mount('/content/drive')

# Basic cleaning and type conversion

orders_df['order_purchase_timestamp'] = pd.to_datetime(orders_df['order_purchase_timestamp'], errors='coerce')
items_df['price'] = pd.to_numeric(items_df['price'], errors='coerce').fillna(0)
items_df['freight_value'] = pd.to_numeric(items_df['freight_value'], errors='coerce').fillna(0)
payments_df['payment_value'] = pd.to_numeric(payments_df['payment_value'], errors='coerce').fillna(0)

# create item total
items_df['total_item_amount'] = items_df['price'] + items_df['freight_value']

# aggregate payments
payments_sum = payments_df.groupby('order_id', as_index=False)['payment_value'].sum()
payments_sum.rename(columns={'payment_value': 'payment_total'}, inplace=True)

print("Cleaning and basic transforms done.")

# --- START: NEW CELL FOR DELIVERY DELAY ---
print("Calculating delivery and review metrics...")

# Select only the columns we need from orders and reviews
orders_subset = orders_df[['order_id', 'order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']]
reviews_subset = reviews_df[['order_id', 'review_score']]

# Convert all timestamp columns to datetime objects
orders_subset['order_purchase_timestamp'] = pd.to_datetime(orders_subset['order_purchase_timestamp'], errors='coerce')
orders_subset['order_delivered_customer_date'] = pd.to_datetime(orders_subset['order_delivered_customer_date'], errors='coerce')
orders_subset['order_estimated_delivery_date'] = pd.to_datetime(orders_subset['order_estimated_delivery_date'], errors='coerce')

# Merge these two dataframes
delivery_df = orders_subset.merge(reviews_subset, on='order_id', how='left')

# --- Feature Engineering ---
# 1. Calculate Delivery Delay (Actual Delivery - Estimated Delivery)
# We will use .dt.days to get the difference in full days
delivery_df['delivery_delay_days'] = (delivery_df['order_delivered_customer_date'] - delivery_df['order_estimated_delivery_date']).dt.days

# 2. Calculate Delivery Time (Actual Delivery - Purchase)
delivery_df['delivery_time_days'] = (delivery_df['order_delivered_customer_date'] - delivery_df['order_purchase_timestamp']).dt.days

print("New delivery_df with delay metrics created.")
print(delivery_df.head())

# Build MASTER TABLE

master = items_df.merge(
    orders_df[['order_id','customer_id','order_status','order_purchase_timestamp']],
    on='order_id', how='left'
).merge(
    products_df[['product_id','product_category_name']],
    on='product_id', how='left'
).merge(
    customers_df[['customer_id','customer_unique_id','customer_city','customer_state']],
    on='customer_id', how='left'
).merge(
    payments_sum, on='order_id', how='left'
).merge(  # <--- THIS IS THE NEWLY ADDED BLOCK IN THE CORRECT LOCATION
    delivery_df[['order_id', 'review_score', 'delivery_delay_days', 'delivery_time_days']],
    on='order_id', how='left'
) # <--- The final closing parenthesis is now here

# add English translation
master = master.merge(
    translation_df[['product_category_name','product_category_name_english']],
    on='product_category_name',
    how='left'
)

master['payment_total'] = master['payment_total'].fillna(master['total_item_amount'])

print("MASTER TABLE created:", master.shape)
master.head()

# Data quality checks (no external libs required)
import os, pandas as pd, numpy as np
os.makedirs('outputs/qc', exist_ok=True)

print("master shape:", getattr(master, "shape", "master missing"))

# Nulls report
null_report = master.isnull().sum().reset_index()
null_report.columns = ['column', 'null_count']
null_report['null_pct'] = (null_report['null_count'] / len(master) * 100).round(3)
null_report.to_csv('outputs/qc/null_report.csv', index=False)
print("Saved: outputs/qc/null_report.csv")

# Numeric stats
numeric_stats = master.select_dtypes(include=[np.number]).describe().transpose()
numeric_stats.to_csv('outputs/qc/numeric_stats.csv')
print("Saved: outputs/qc/numeric_stats.csv")

# Basic logical checks
checks = []
if 'price' in master.columns:
    checks.append({'column':'price','min':float(master['price'].min()),'max':float(master['price'].max()),
                   'negatives':bool((master['price']<0).any())})
if 'total_item_amount' in master.columns:
    checks.append({'column':'total_item_amount','min':float(master['total_item_amount'].min()),'max':float(master['total_item_amount'].max()),
                   'negatives':bool((master['total_item_amount']<0).any())})
pd.DataFrame(checks).to_csv('outputs/qc/schema_basic_checks.csv', index=False)
print("Saved: outputs/qc/schema_basic_checks.csv")

# Cell B: Diagnostic plotting — recreates & displays key plots inline and saves PNGs
import os, glob, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
os.makedirs('outputs/figures', exist_ok=True)

print("MASTER SHAPE:", master.shape)
print("Columns:", master.columns.tolist())

# Ensure datetimes and derived fields
if 'order_purchase_timestamp' in master.columns:
    master['order_purchase_timestamp'] = pd.to_datetime(master['order_purchase_timestamp'], errors='coerce')
    master = master.dropna(subset=['order_purchase_timestamp']).copy()
    master['order_date'] = master['order_purchase_timestamp'].dt.floor('D')
    master['order_month'] = master['order_purchase_timestamp'].dt.to_period('M').astype(str)
else:
    print("No 'order_purchase_timestamp' column; time plots will be skipped.")

def save_show(fig, fname):
    fig.savefig(fname, bbox_inches='tight')
    print("Saved:", fname)
    plt.show()

# Monthly revenue
try:
    if 'order_month' in master.columns:
        monthly = master.groupby('order_month', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'monthly_revenue'})
        monthly['month_start'] = pd.to_datetime(monthly['order_month'] + '-01')
        fig, ax = plt.subplots(figsize=(12,5))
        ax.plot(monthly['month_start'], monthly['monthly_revenue'], marker='o', linewidth=1)
        ax.set_title('Monthly Revenue Trend')
        ax.set_xlabel('Month'); ax.set_ylabel('Revenue'); ax.grid(alpha=0.2)
        save_show(fig, 'outputs/figures/monthly_revenue_trend.png')
    else:
        print("Skipping monthly plot: 'order_month' missing")
except Exception as e:
    print("Monthly plot error:", e)

# Weekly revenue
try:
    if 'order_date' in master.columns:
        daily = master.groupby('order_date', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'daily_revenue'})
        daily['order_date'] = pd.to_datetime(daily['order_date'])
        daily = daily.set_index('order_date').sort_index()
        weekly = daily.resample('7D').sum().reset_index()
        fig, ax = plt.subplots(figsize=(12,4))
        ax.plot(weekly['order_date'], weekly['daily_revenue'], marker='o', linewidth=1)
        ax.set_title('Weekly-summed Revenue (7-day)')
        save_show(fig, 'outputs/figures/weekly_revenue_trend.png')
    else:
        print("Skipping weekly plot: 'order_date' missing")
except Exception as e:
    print("Weekly plot error:", e)

# Top categories
try:
    if 'product_category_name_english' in master.columns:
        cat_rev = master.groupby('product_category_name_english', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'category_revenue'}).sort_values('category_revenue', ascending=False)
        fig, ax = plt.subplots(figsize=(10,6))
        sns.barplot(data=cat_rev.head(10), x='category_revenue', y='product_category_name_english', ax=ax)
        ax.set_title('Top 10 Categories by Revenue')
        save_show(fig, 'outputs/figures/top10_categories_revenue.png')
    else:
        print("Skipping categories plot: 'product_category_name_english' missing")
except Exception as e:
    print("Category plot error:", e)

# Top states
try:
    if 'customer_state' in master.columns:
        state_rev = master.groupby('customer_state', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'state_revenue'}).sort_values('state_revenue', ascending=False)
        fig, ax = plt.subplots(figsize=(10,5))
        sns.barplot(data=state_rev.head(10), x='state_revenue', y='customer_state', ax=ax)
        ax.set_title('Top 10 States by Revenue')
        save_show(fig, 'outputs/figures/top_states_revenue.png')
    else:
        print("Skipping state plot: 'customer_state' missing")
except Exception as e:
    print("State plot error:", e)

# Order status (robust creation)
try:
    if 'order_status' in master.columns:
        order_status_counts = master['order_status'].value_counts().rename_axis('order_status').reset_index(name='count')
        print(order_status_counts.head())
        fig, ax = plt.subplots(figsize=(9,4))
        sns.barplot(data=order_status_counts, x='order_status', y='count', order=order_status_counts['order_status'], ax=ax)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        ax.set_title('Order Status Distribution')
        save_show(fig, 'outputs/figures/order_status_distribution.png')
    else:
        print("Skipping order_status plot: 'order_status' missing")
except Exception as e:
    print("Order status plot error:", e)

# Final: list saved figures
print("\nSaved figures:")
for f in sorted(glob.glob('outputs/figures/*.png')):
    print("-", f)

# Export summary CSVs to outputs/tables for the report
import os
os.makedirs('outputs/tables', exist_ok=True)

# Monthly and weekly CSVs
if 'monthly' in globals():
    monthly.to_csv('outputs/tables/monthly_revenue.csv', index=False)
if 'weekly' in globals():
    weekly.to_csv('outputs/tables/weekly_revenue.csv', index=False)

# Category
if 'cat_rev' in globals():
    cat_rev.to_csv('outputs/tables/category_revenue.csv', index=False)

# States and cities
if 'state_rev' in globals():
    state_rev.to_csv('outputs/tables/state_revenue.csv', index=False)
if 'city_rev' in globals():
    city_rev.to_csv('outputs/tables/top_cities.csv', index=False)

# Top customers
if 'top_customers' not in globals() and 'customer_unique_id' in master.columns:
    top_customers = master.groupby('customer_unique_id', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'customer_revenue'}).sort_values('customer_revenue', ascending=False).head(10)
if 'top_customers' in globals():
    top_customers.to_csv('outputs/tables/top_customers.csv', index=False)

print("Saved CSV summaries in outputs/tables (if present).")
print("List table files:")
import glob
for f in sorted(glob.glob('outputs/tables/*.csv')):
    print("-", f)

# Save analytical tables into sqlite DB and list tables
from sqlalchemy import create_engine, text
import os
DB_PATH = '/content/project3/data/ecommerce_analytics.db'
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
engine = create_engine(f"sqlite:///{DB_PATH}")

to_save = {}
if 'monthly' in globals():
    to_save['monthly_sales'] = monthly
if 'cat_rev' in globals():
    to_save['sales_by_category'] = cat_rev
if 'state_rev' in globals():
    to_save['state_summary'] = state_rev
if 'top_customers' in globals():
    to_save['top_customers'] = top_customers
if 'weekly' in globals():
    to_save['weekly_revenue'] = weekly

for name, df in to_save.items():
    try:
        df.to_sql(name, engine, if_exists='replace', index=False)
        print(f"Saved table {name} ({len(df)} rows)")
    except Exception as e:
        print("Could not save", name, "->", e)

with engine.connect() as conn:
    res = conn.execute(text("SELECT name FROM sqlite_master WHERE type='table';"))
    tables = [r[0] for r in res.fetchall()]
print("DB tables now:", tables)

# Create ZIP of project3 and show path
import zipfile, os
root = '/content/project3'
zip_path = '/content/project3_output.zip'

if os.path.exists(root):
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        for foldername, subfolders, filenames in os.walk(root):
            for filename in filenames:
                filepath = os.path.join(foldername, filename)
                # skip very large or hidden files if you like (optional)
                zf.write(filepath, os.path.relpath(filepath, '/content'))
    print("ZIP created at", zip_path, "size MB:", os.path.getsize(zip_path)/1024/1024)
else:
    print("Project folder not found at", root)

# To download in Colab:
try:
    from google.colab import files
    files.download(zip_path)
except Exception as e:
    print("Files.download failed (if not in Colab). You can fetch from the left 'Files' panel.")

# Data quality checks and QC artifacts


# Install pandera if not installed (uncomment if needed)
# !pip install pandera --quiet

import pandas as pd, numpy as np, os
import pandera as pa
from pandera import Column, Check

os.makedirs('outputs/qc', exist_ok=True)

print("master shape:", master.shape)

# Basic nulls and types report
null_report = master.isnull().sum().reset_index().rename(columns={'index':'column', 0:'null_count'})
null_report['null_pct'] = (null_report['null_count'] / len(master) * 100).round(3)
null_report.to_csv('outputs/qc/null_report.csv', index=False)
print("Saved: outputs/qc/null_report.csv")

# Basic stats for numeric cols
num_stats = master.select_dtypes(include=[np.number]).describe().transpose()
num_stats.to_csv('outputs/qc/numeric_stats.csv')
print("Saved: outputs/qc/numeric_stats.csv")

# Simple schema validation (lightweight)
schema_dict = {}
# Example checks - expand as you like
if 'order_id' in master.columns:
    schema_dict['order_id'] = Column(pa.String, nullable=False)
if 'order_purchase_timestamp' in master.columns:
    schema_dict['order_purchase_timestamp'] = Column(pa.DateTime, nullable=False)
if 'price' in master.columns:
    schema_dict['price'] = Column(pa.Float, Check.ge(0))
if 'total_item_amount' in master.columns:
    schema_dict['total_item_amount'] = Column(pa.Float, Check.ge(0))

if schema_dict:
    schema = pa.DataFrameSchema(schema_dict)
    try:
        validated = schema.validate(master, lazy=True)
        print("Schema validation passed. Rows:", len(validated))
        pd.DataFrame({"schema_status":["passed"]}).to_csv('outputs/qc/schema_status.csv', index=False)
    except pa.errors.SchemaErrors as e:
        print("Schema validation failed (saving details).")
        # convert errors to DataFrame for artifact
        err = e.failure_cases
        err.to_csv('outputs/qc/schema_failures.csv', index=False)
        print("Saved: outputs/qc/schema_failures.csv")
else:
    print("No schema checks defined (no matching columns).")

# Diagnostic plotting cell — paste this right after the cell that creates `master` and run it.
import os, glob
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

os.makedirs('outputs/figures', exist_ok=True)

print("MASTER SHAPE:", getattr(master, "shape", "master missing"))
print("Available columns:", master.columns.tolist())

# Helper to show and save plot
def save_and_show(fig, fname):
    fig.savefig(fname, bbox_inches='tight')
    print("Saved:", fname)
    plt.show()

# 1) Quick sample of key columns
check_cols = ['order_purchase_timestamp','total_item_amount','order_month','order_date',
              'product_category_name_english','price','customer_state','customer_city','order_status']
for c in check_cols:
    print(f"\nColumn '{c}':", "PRESENT" if c in master.columns else "MISSING")
    if c in master.columns:
        print(master[c].dropna().head(5).to_list())

# Ensure timestamp parsed
if 'order_purchase_timestamp' in master.columns:
    master['order_purchase_timestamp'] = pd.to_datetime(master['order_purchase_timestamp'], errors='coerce')
    master = master.dropna(subset=['order_purchase_timestamp']).copy()
    master['order_date'] = master['order_purchase_timestamp'].dt.floor('D')
    master['order_month'] = master['order_purchase_timestamp'].dt.to_period('M').astype(str)
else:
    print("No order_purchase_timestamp; time plots will be skipped.")

# ---------- Monthly revenue ----------
try:
    if 'order_month' in master.columns:
        monthly = master.groupby('order_month', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'monthly_revenue'})
        monthly['month_start'] = pd.to_datetime(monthly['order_month'] + '-01')
        fig, ax = plt.subplots(figsize=(12,5))
        ax.plot(monthly['month_start'], monthly['monthly_revenue'], marker='o', linewidth=1)
        ax.set_title('Monthly Revenue Trend')
        ax.set_xlabel('Month'); ax.set_ylabel('Revenue')
        ax.grid(alpha=0.2)
        save_and_show(fig, 'outputs/figures/diagnostic_monthly_revenue_trend.png')
    else:
        print("Skipping monthly: 'order_month' not present")
except Exception as e:
    print("Monthly plot error:", e)

# ---------- Weekly-summed revenue ----------
try:
    if 'order_date' in master.columns:
        daily = master.groupby('order_date', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'daily_revenue'})
        daily['order_date'] = pd.to_datetime(daily['order_date'])
        daily = daily.set_index('order_date').sort_index()
        weekly = daily.resample('7D').sum().reset_index()
        fig, ax = plt.subplots(figsize=(12,4))
        ax.plot(weekly['order_date'], weekly['daily_revenue'], marker='o', linewidth=1)
        ax.set_title('Weekly-summed Revenue (7-day buckets)')
        ax.set_xlabel('Date'); ax.set_ylabel('Revenue'); ax.grid(alpha=0.2)
        save_and_show(fig, 'outputs/figures/diagnostic_weekly_revenue_trend.png')
    else:
        print("Skipping weekly: 'order_date' not present")
except Exception as e:
    print("Weekly plot error:", e)

# ---------- Top categories by revenue ----------
try:
    if 'product_category_name_english' in master.columns:
        cat_rev = master.groupby('product_category_name_english', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'category_revenue'}).sort_values('category_revenue', ascending=False)
        print("\nTop 5 categories (by revenue):")
        print(cat_rev.head(5))
        fig, ax = plt.subplots(figsize=(10,6))
        sns.barplot(data=cat_rev.head(10), x='category_revenue', y='product_category_name_english', ax=ax)
        ax.set_title('Top 10 Categories by Revenue')
        save_and_show(fig, 'outputs/figures/diagnostic_top10_categories_revenue.png')
    else:
        print("Skipping categories: 'product_category_name_english' not present")
except Exception as e:
    print("Category plot error:", e)

# ---------- Top states ----------
try:
    if 'customer_state' in master.columns:
        state_rev = master.groupby('customer_state', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'state_revenue'}).sort_values('state_revenue', ascending=False)
        print("\nTop 5 states by revenue:")
        print(state_rev.head(5))
        fig, ax = plt.subplots(figsize=(10,5))
        sns.barplot(data=state_rev.head(10), x='state_revenue', y='customer_state', ax=ax)
        ax.set_title('Top 10 States by Revenue')
        save_and_show(fig, 'outputs/figures/diagnostic_top_states_revenue.png')
    else:
        print("Skipping states: 'customer_state' not present")
except Exception as e:
    print("State plot error:", e)

# ---------- Top cities ----------
try:
    if 'customer_city' in master.columns:
        city_rev = master.groupby('customer_city', as_index=False)['total_item_amount'].sum().rename(columns={'total_item_amount':'city_revenue'}).sort_values('city_revenue', ascending=False).head(15)
        print("\nTop 5 cities by revenue:")
        print(city_rev.head(5))
        fig, ax = plt.subplots(figsize=(10,6))
        sns.barplot(data=city_rev, x='city_revenue', y='customer_city', ax=ax)
        ax.set_title('Top 15 Cities by Revenue')
        save_and_show(fig, 'outputs/figures/diagnostic_top_cities_revenue.png')
    else:
        print("Skipping cities: 'customer_city' not present")
except Exception as e:
    print("City plot error:", e)

# ---------- Order status distribution ----------
try:
    if 'order_status' in master.columns:
        order_status_counts = master['order_status'].value_counts().rename_axis('order_status').reset_index(name='count')
        print("\nOrder status sample:")
        print(order_status_counts.head(10))
        fig, ax = plt.subplots(figsize=(9,4))
        sns.barplot(data=order_status_counts, x='order_status', y='count', order=order_status_counts['order_status'], ax=ax)
        ax.set_title('Order Status Distribution')
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        save_and_show(fig, 'outputs/figures/diagnostic_order_status_distribution.png')
    else:
        print("Skipping order_status: column not present")
except Exception as e:
    print("Order status plot error:", e)

# ---------- List saved images ----------
imgs = sorted(glob.glob("outputs/figures/*.png"))
print("\nSaved image files (diagnostic):")
for f in imgs:
    print("-", f)

from IPython.display import Image, display, HTML
import glob, os

imgs = sorted(glob.glob("outputs/figures/*.png"))

# Create the HTML wrapper
html = "<div style='display:flex; flex-wrap:wrap;'>"

print(f"Displaying {len(imgs)} saved images:")

for p in imgs:
    # Add each image to the HTML string using its path
    html += f"""
    <div style='margin:10px; border: 1px solid #ccc; padding: 5px;'>
        <img src='{p}' width=400>
        <div style='font-size:12px; text-align:center;'>{os.path.basename(p)}</div>
    </div>
    """

html += "</div>"

# Display the final HTML
display(HTML(html))

from sqlalchemy import create_engine, text
import os

DB_PATH = '/content/project3/data/ecommerce_analytics.db'
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
engine = create_engine(f"sqlite:///{DB_PATH}")

# Save if exist in workspace
to_save = {}
if 'monthly' in locals():
    to_save['monthly_sales'] = monthly
if 'cat_rev' in locals():
    to_save['sales_by_category'] = cat_rev
if 'state_rev' in locals():
    to_save['state_summary'] = state_rev
if 'top_customers' in locals():
    to_save['top_customers'] = top_customers
if 'weekly' in locals():
    to_save['weekly_revenue'] = weekly
if 'delivery_saved' in locals() and delivery_saved:
    if 'delivery_summary_df' in locals() and not delivery_summary_df.empty:
        to_save['delivery_summary'] = delivery_summary_df
    else:
        # create a simple delivery summary if possible
        if 'delivery_delay_days' in master.columns:
            ds = master.groupby('order_status', as_index=False)['delivery_delay_days'].mean().rename(columns={'delivery_delay_days':'avg_delay_days'})
            to_save['delivery_summary'] = ds

for name, df in to_save.items():
    try:
        df.to_sql(name, engine, if_exists='replace', index=False)
        print(f"Saved table {name} to DB")
    except Exception as e:
        print("Could not save", name, "->", e)

# show tables
with engine.connect() as conn:
    res = conn.execute(text("SELECT name FROM sqlite_master WHERE type='table';"))
    tables = [r[0] for r in res.fetchall()]
print("DB tables now:", tables)

import os
import numpy as np, pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import joblib
import matplotlib.pyplot as plt, seaborn as sns

# check
if 'delivery_delay_days' not in master.columns:
    print("No 'delivery_delay_days' column - skipping ML.")
else:
    df_ml = master.dropna(subset=['delivery_delay_days']).copy()
    df_ml['delayed'] = (df_ml['delivery_delay_days'] > 3).astype(int)
    # pick numeric features automatically
    num_cols = df_ml.select_dtypes(include=[np.number]).columns.tolist()
    num_cols = [c for c in num_cols if c not in ['delivery_delay_days','delayed']]
    num_cols = num_cols[:30]  # limit to 30 features
    if len(num_cols) < 3:
        print("Not enough numeric features for ML model.")
    else:
        X = df_ml[num_cols].fillna(0)
        y = df_ml['delayed']
        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
        clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        report = classification_report(y_test, y_pred, output_dict=True)
        pd.DataFrame(report).transpose().to_csv('outputs/tables/delay_model_report.csv')
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(4,3)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues'); plt.title('Confusion Matrix - Delay Classifier'); plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.tight_layout(); plt.savefig('outputs/figures/delay_confusion_matrix.png'); plt.close()
        print("Saved ML report and confusion matrix.")

        # feature importances
        fi = pd.DataFrame({'feature': X_train.columns, 'importance': clf.feature_importances_}).sort_values('importance', ascending=False).head(20)
        fi.to_csv('outputs/tables/delay_feature_importance.csv', index=False)
        print("Saved feature importances.")

        # SHAP (optional install)
        try:
            import shap
            explainer = shap.Explainer(clf, X_train)
            sample = X_test.sample(min(500, len(X_test)), random_state=42)
            shap_values = explainer(sample)
            # summary plot -> save
            plt.figure()
            shap.plots.beeswarm(shap_values, show=False)
            plt.tight_layout()
            plt.savefig('outputs/figures/shap_delay_beeswarm.png', bbox_inches='tight')
            plt.close()
            print("Saved SHAP beeswarm plot.")
        except Exception as e:
            print("SHAP not run or failed:", e)

# ---  (MODEL EXPLAINABILITY) ---

# We need to install the SHAP library first
!pip install shap --quiet

import shap
import matplotlib.pyplot as plt

print("\n--- Starting Model Explainability (SHAP) ---")

# Check if the model 'clf' exists from the previous cell
if 'clf' in locals():

    # 1. Create the explainer
    # We use the 'clf' (our RandomForestClassifier) and the 'X_train' data
    explainer = shap.TreeExplainer(clf)

    # 2. Calculate SHAP values
    # We'll take a sample of the test data to speed things up
    X_test_sample = X_test.sample(1000, random_state=42)
    shap_values = explainer.shap_values(X_test_sample)

    print("SHAP values calculated.")

    # 3. Create the summary plot
    # We are plotting for "Class 1" which means "Delayed"
    print("--- SHAP Summary Plot ---")
    shap.summary_plot(shap_values[1], X_test_sample, plot_type="bar", title="Feature Importance for Predicting Delay")
    plt.show()

else:
    print("--- ERROR ---")
    print("The model 'clf' is not defined.")
    print("Please run the Machine Learning cell (the one above this) before running the SHAP cell.")

#Aggregation (business insights)
cat_col = 'product_category_name_english'
sales_summary = master.groupby(cat_col, as_index=False)['total_item_amount'].sum()
sales_summary.rename(columns={'total_item_amount':'category_revenue'}, inplace=True)
sales_summary = sales_summary.sort_values('category_revenue', ascending=False)

print("Sales by category created.")
sales_summary.head()

# Save to SQLite database (LOAD)


from sqlalchemy import create_engine, text

DB_PATH = os.path.join(BASE, "data", "ecommerce_analytics.db")
engine = create_engine(f"sqlite:///{DB_PATH}")

# Write tables
sales_summary.to_sql('sales_by_category', engine, if_exists='replace', index=False)
master.to_sql('fact_orders', engine, if_exists='replace', index=False)

print("Database created at:", DB_PATH)

# Correct SQLAlchemy 2.x syntax for raw SQL execution
with engine.connect() as conn:
    result = conn.execute(text("SELECT name FROM sqlite_master WHERE type='table';"))
    tables = result.fetchall()
    print("Tables in database:", tables)

# SQL queries inside Colab
query = """
SELECT product_category_name_english, category_revenue
FROM sales_by_category
ORDER BY category_revenue DESC
LIMIT 5;
"""

top5 = pd.read_sql(query, engine)
print(top5)

plt.figure(figsize=(10,6))
sns.barplot(data=top5, x='category_revenue', y='product_category_name_english')
plt.title("Top 5 Categories by Revenue")
plt.show()

